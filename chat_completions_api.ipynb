{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6c109a9-b5ce-41d7-b82d-9352758630af",
   "metadata": {},
   "source": [
    "# My Personal Notes For Learning ChatGPT API\n",
    "### https://github.com/mmrzax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a66a777f-e896-4f32-94b3-a19124766d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25a82447-1e03-48d6-b921-86632ada77d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get openai api key from enviroment\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "# print(openai.api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700d5143-f708-4bfb-b03f-ddc298f50058",
   "metadata": {},
   "source": [
    "### Messages and Roles\n",
    "\n",
    "The main input is the messages parameter. Messages must be an array of message objects, where each object has a role (either \"system\", \"user\", or \"assistant\") and content. Conversations can be as short as one message or many back and forth turns.\n",
    "\n",
    "Typically, a conversation is formatted with a system message first, followed by alternating user and assistant messages.\n",
    "\n",
    "The system message helps set the behavior of the assistant. For example, you can modify the personality of the assistant or provide specific instructions about how it should behave throughout the conversation. However note that the system message is optional and the model’s behavior without a system message is likely to be similar to using a generic message such as \"You are a helpful assistant.\"\n",
    "\n",
    "The user messages provide requests or comments for the assistant to respond to. Assistant messages store previous assistant responses, but can also be written by you to give examples of desired behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca6b5b9-5a9d-4393-af7d-e8d2d786ea0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "res1 = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are an engineer and assistant, skilled in control systems.\"},\n",
    "    {\"role\": \"user\", \"content\": \"In your opinion, what is the best part of industries that can be controlled by artificial intelligence?\"}\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11dc1191-7c65-450f-af75-cc8a3bb85cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "res2 = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Who won the world series in 2020?\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"The Los Angeles Dodgers won the World Series in 2020.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Where was it played?\"}\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fee868d-f07a-4901-9ac5-21520f89f0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "res3 = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"assistant\", \"content\": \"Persepolis lose the game to Kashima Antlers AFC Final\"},\n",
    "        {\"role\": \"user\", \"content\": \"Where was it played?\"}\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3782ddf0-85db-4e55-aea7-0fd6d06e6e63",
   "metadata": {},
   "source": [
    "**دلیل آوردن یک سری مکالمات قبل از پرامپت اصلی اینه که چت بات بتونه بفهمه اصلا منظور ما از سوال آخر یعنی بازیه کجا پلی شده کدوم بازی هست<br>در کل این تاریخچه چت خیلی مهمه و هر بار باید سیوش کرد و اگه به محدودیت سایز توکن رسیدیم باید از شکل کوتاه شده استفاده کنیم در این [لینک](https://platform.openai.com/docs/guides/gpt-best-practices/tactic-for-dialogue-applications-that-require-very-long-conversations-summarize-or-filter-previous-dialogue) توضیح داده شده**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67efce2d-065a-45bd-ae54-a48d296e810f",
   "metadata": {},
   "source": [
    "**در اینجا میخواهیم به بات بگیم که از یه تابع کمکی برای پاسخ دادن به کاربر استفاده کنه، برای مثال در اینجا یک تابع کمکی که با یک ریکوئست دمای هوا رو میگیره نوشتم**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9de42f32-9b7c-472e-a2b0-e21d7f5908d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tehran: 🌫  🌡️+15°C 🌬️↓4km/h\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_current_weather(location: str, unit: str = \"celcius\"):\n",
    "    units: dict[str, str] = {\"celsius\": \"m\", \"fahrenheit\": \"u\"}\n",
    "    # r = requests.get(f\"https://wttr.in/{location}?{units.get(unit)}&format=3\")\n",
    "    r = requests.get(f\"https://wttr.in/{location}?{units.get(unit)}&format=4\")\n",
    "    return r.text\n",
    "print(get_current_weather(\"Tehran\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81f7906e-5548-4f2a-a3de-5ac45eafc097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "آب و هوای شهر تهران در حال حاضر پوشیده از مه است، دما حدود +15 درجه سانتیگراد و سرعت باد حدود 4 کیلومتر در ساعت به سمت پایین است.\n"
     ]
    }
   ],
   "source": [
    "def run_conversation():\n",
    "    # Step 1: send the conversation and available functions to GPT\n",
    "    messages = [{\"role\": \"user\", \"content\": \"آب و هوای شهر تهران هم اکنون چگونه است؟\"}]\n",
    "    functions = [\n",
    "        {\n",
    "            \"name\": \"get_current_weather\",\n",
    "            \"description\": \"آب و هوا کنونی را برای مکان داده شده دریافت کن\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"location\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"نام مکان به زبان انگلیسی، برای مثال Tehran\",\n",
    "                    },\n",
    "                    \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]},\n",
    "                },\n",
    "                \"required\": [\"location\"],\n",
    "            },\n",
    "        }\n",
    "    ]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo-0613\",\n",
    "        messages=messages,\n",
    "        functions=functions,\n",
    "        function_call=\"auto\",  # auto is default, but we'll be explicit\n",
    "    )\n",
    "    response_message = response[\"choices\"][0][\"message\"]\n",
    "\n",
    "    # Step 2: check if GPT wanted to call a function\n",
    "    if response_message.get(\"function_call\"):\n",
    "        # Step 3: call the function\n",
    "        # Note: the JSON response may not always be valid; be sure to handle errors\n",
    "        available_functions = {\n",
    "            \"get_current_weather\": get_current_weather,\n",
    "        }  # only one function in this example, but you can have multiple\n",
    "        function_name = response_message[\"function_call\"][\"name\"]\n",
    "        function_to_call = available_functions[function_name]\n",
    "        function_args = json.loads(response_message[\"function_call\"][\"arguments\"])\n",
    "        function_response = function_to_call(\n",
    "            location=function_args.get(\"location\"),\n",
    "            unit=function_args.get(\"unit\"),\n",
    "        )\n",
    "\n",
    "        # Step 4: send the info on the function call and function response to GPT\n",
    "        messages.append(response_message)  # extend conversation with assistant's reply\n",
    "        messages.append(\n",
    "            {\n",
    "                \"role\": \"function\",\n",
    "                \"name\": function_name,\n",
    "                \"content\": function_response,\n",
    "            }\n",
    "        )  # extend conversation with function response\n",
    "        second_response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo-0613\",\n",
    "            messages=messages,\n",
    "        )  # get a new response from GPT where it can see the function response\n",
    "        return second_response[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "print(run_conversation())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59e70e7-0e05-4f17-96f1-69314d86c772",
   "metadata": {},
   "source": [
    "**ممکن است مدل بخواهد توابعی را فراخوانی کند که بهش ارائه نشده، برای رفع این مشکل از یک پیام با نقش سیستم استفاده کنید و بگید که فقط از توابعی که ارائه شده استفاده کن**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
