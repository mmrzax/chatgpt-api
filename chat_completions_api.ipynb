{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6c109a9-b5ce-41d7-b82d-9352758630af",
   "metadata": {},
   "source": [
    "# My Personal Notes For Learning ChatGPT API\n",
    "### https://github.com/mmrzax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a66a777f-e896-4f32-94b3-a19124766d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25a82447-1e03-48d6-b921-86632ada77d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get openai api key from enviroment\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "# print(openai.api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700d5143-f708-4bfb-b03f-ddc298f50058",
   "metadata": {},
   "source": [
    "### Messages and Roles\n",
    "\n",
    "The main input is the messages parameter. Messages must be an array of message objects, where each object has a role (either \"system\", \"user\", or \"assistant\") and content. Conversations can be as short as one message or many back and forth turns.\n",
    "\n",
    "Typically, a conversation is formatted with a system message first, followed by alternating user and assistant messages.\n",
    "\n",
    "The system message helps set the behavior of the assistant. For example, you can modify the personality of the assistant or provide specific instructions about how it should behave throughout the conversation. However note that the system message is optional and the modelâ€™s behavior without a system message is likely to be similar to using a generic message such as \"You are a helpful assistant.\"\n",
    "\n",
    "The user messages provide requests or comments for the assistant to respond to. Assistant messages store previous assistant responses, but can also be written by you to give examples of desired behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca6b5b9-5a9d-4393-af7d-e8d2d786ea0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "res1 = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are an engineer and assistant, skilled in control systems.\"},\n",
    "    {\"role\": \"user\", \"content\": \"In your opinion, what is the best part of industries that can be controlled by artificial intelligence?\"}\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11dc1191-7c65-450f-af75-cc8a3bb85cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "res2 = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Who won the world series in 2020?\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"The Los Angeles Dodgers won the World Series in 2020.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Where was it played?\"}\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fee868d-f07a-4901-9ac5-21520f89f0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "res3 = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"assistant\", \"content\": \"Persepolis lose the game to Kashima Antlers AFC Final\"},\n",
    "        {\"role\": \"user\", \"content\": \"Where was it played?\"}\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3782ddf0-85db-4e55-aea7-0fd6d06e6e63",
   "metadata": {},
   "source": [
    "**Ø¯Ù„ÛŒÙ„ Ø¢ÙˆØ±Ø¯Ù† ÛŒÚ© Ø³Ø±ÛŒ Ù…Ú©Ø§Ù„Ù…Ø§Øª Ù‚Ø¨Ù„ Ø§Ø² Ù¾Ø±Ø§Ù…Ù¾Øª Ø§ØµÙ„ÛŒ Ø§ÛŒÙ†Ù‡ Ú©Ù‡ Ú†Øª Ø¨Ø§Øª Ø¨ØªÙˆÙ†Ù‡ Ø¨ÙÙ‡Ù…Ù‡ Ø§ØµÙ„Ø§ Ù…Ù†Ø¸ÙˆØ± Ù…Ø§ Ø§Ø² Ø³ÙˆØ§Ù„ Ø¢Ø®Ø± ÛŒØ¹Ù†ÛŒ Ø¨Ø§Ø²ÛŒÙ‡ Ú©Ø¬Ø§ Ù¾Ù„ÛŒ Ø´Ø¯Ù‡ Ú©Ø¯ÙˆÙ… Ø¨Ø§Ø²ÛŒ Ù‡Ø³Øª<br>Ø¯Ø± Ú©Ù„ Ø§ÛŒÙ† ØªØ§Ø±ÛŒØ®Ú†Ù‡ Ú†Øª Ø®ÛŒÙ„ÛŒ Ù…Ù‡Ù…Ù‡ Ùˆ Ù‡Ø± Ø¨Ø§Ø± Ø¨Ø§ÛŒØ¯ Ø³ÛŒÙˆØ´ Ú©Ø±Ø¯ Ùˆ Ø§Ú¯Ù‡ Ø¨Ù‡ Ù…Ø­Ø¯ÙˆØ¯ÛŒØª Ø³Ø§ÛŒØ² ØªÙˆÚ©Ù† Ø±Ø³ÛŒØ¯ÛŒÙ… Ø¨Ø§ÛŒØ¯ Ø§Ø² Ø´Ú©Ù„ Ú©ÙˆØªØ§Ù‡ Ø´Ø¯Ù‡ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒÙ… Ø¯Ø± Ø§ÛŒÙ† [Ù„ÛŒÙ†Ú©](https://platform.openai.com/docs/guides/gpt-best-practices/tactic-for-dialogue-applications-that-require-very-long-conversations-summarize-or-filter-previous-dialogue) ØªÙˆØ¶ÛŒØ­ Ø¯Ø§Ø¯Ù‡ Ø´Ø¯Ù‡**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67efce2d-065a-45bd-ae54-a48d296e810f",
   "metadata": {},
   "source": [
    "**Ø¯Ø± Ø§ÛŒÙ†Ø¬Ø§ Ù…ÛŒØ®ÙˆØ§Ù‡ÛŒÙ… Ø¨Ù‡ Ø¨Ø§Øª Ø¨Ú¯ÛŒÙ… Ú©Ù‡ Ø§Ø² ÛŒÙ‡ ØªØ§Ø¨Ø¹ Ú©Ù…Ú©ÛŒ Ø¨Ø±Ø§ÛŒ Ù¾Ø§Ø³Ø® Ø¯Ø§Ø¯Ù† Ø¨Ù‡ Ú©Ø§Ø±Ø¨Ø± Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†Ù‡ØŒ Ø¨Ø±Ø§ÛŒ Ù…Ø«Ø§Ù„ Ø¯Ø± Ø§ÛŒÙ†Ø¬Ø§ ÛŒÚ© ØªØ§Ø¨Ø¹ Ú©Ù…Ú©ÛŒ Ú©Ù‡ Ø¨Ø§ ÛŒÚ© Ø±ÛŒÚ©ÙˆØ¦Ø³Øª Ø¯Ù…Ø§ÛŒ Ù‡ÙˆØ§ Ø±Ùˆ Ù…ÛŒÚ¯ÛŒØ±Ù‡ Ù†ÙˆØ´ØªÙ…**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9de42f32-9b7c-472e-a2b0-e21d7f5908d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tehran: ğŸŒ«  ğŸŒ¡ï¸+15Â°C ğŸŒ¬ï¸â†“4km/h\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_current_weather(location: str, unit: str = \"celcius\"):\n",
    "    units: dict[str, str] = {\"celsius\": \"m\", \"fahrenheit\": \"u\"}\n",
    "    # r = requests.get(f\"https://wttr.in/{location}?{units.get(unit)}&format=3\")\n",
    "    r = requests.get(f\"https://wttr.in/{location}?{units.get(unit)}&format=4\")\n",
    "    return r.text\n",
    "print(get_current_weather(\"Tehran\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81f7906e-5548-4f2a-a3de-5ac45eafc097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ø¢Ø¨ Ùˆ Ù‡ÙˆØ§ÛŒ Ø´Ù‡Ø± ØªÙ‡Ø±Ø§Ù† Ø¯Ø± Ø­Ø§Ù„ Ø­Ø§Ø¶Ø± Ù¾ÙˆØ´ÛŒØ¯Ù‡ Ø§Ø² Ù…Ù‡ Ø§Ø³ØªØŒ Ø¯Ù…Ø§ Ø­Ø¯ÙˆØ¯ +15 Ø¯Ø±Ø¬Ù‡ Ø³Ø§Ù†ØªÛŒÚ¯Ø±Ø§Ø¯ Ùˆ Ø³Ø±Ø¹Øª Ø¨Ø§Ø¯ Ø­Ø¯ÙˆØ¯ 4 Ú©ÛŒÙ„ÙˆÙ…ØªØ± Ø¯Ø± Ø³Ø§Ø¹Øª Ø¨Ù‡ Ø³Ù…Øª Ù¾Ø§ÛŒÛŒÙ† Ø§Ø³Øª.\n"
     ]
    }
   ],
   "source": [
    "def run_conversation():\n",
    "    # Step 1: send the conversation and available functions to GPT\n",
    "    messages = [{\"role\": \"user\", \"content\": \"Ø¢Ø¨ Ùˆ Ù‡ÙˆØ§ÛŒ Ø´Ù‡Ø± ØªÙ‡Ø±Ø§Ù† Ù‡Ù… Ø§Ú©Ù†ÙˆÙ† Ú†Ú¯ÙˆÙ†Ù‡ Ø§Ø³ØªØŸ\"}]\n",
    "    functions = [\n",
    "        {\n",
    "            \"name\": \"get_current_weather\",\n",
    "            \"description\": \"Ø¢Ø¨ Ùˆ Ù‡ÙˆØ§ Ú©Ù†ÙˆÙ†ÛŒ Ø±Ø§ Ø¨Ø±Ø§ÛŒ Ù…Ú©Ø§Ù† Ø¯Ø§Ø¯Ù‡ Ø´Ø¯Ù‡ Ø¯Ø±ÛŒØ§ÙØª Ú©Ù†\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"location\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Ù†Ø§Ù… Ù…Ú©Ø§Ù† Ø¨Ù‡ Ø²Ø¨Ø§Ù† Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒØŒ Ø¨Ø±Ø§ÛŒ Ù…Ø«Ø§Ù„ Tehran\",\n",
    "                    },\n",
    "                    \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]},\n",
    "                },\n",
    "                \"required\": [\"location\"],\n",
    "            },\n",
    "        }\n",
    "    ]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo-0613\",\n",
    "        messages=messages,\n",
    "        functions=functions,\n",
    "        function_call=\"auto\",  # auto is default, but we'll be explicit\n",
    "    )\n",
    "    response_message = response[\"choices\"][0][\"message\"]\n",
    "\n",
    "    # Step 2: check if GPT wanted to call a function\n",
    "    if response_message.get(\"function_call\"):\n",
    "        # Step 3: call the function\n",
    "        # Note: the JSON response may not always be valid; be sure to handle errors\n",
    "        available_functions = {\n",
    "            \"get_current_weather\": get_current_weather,\n",
    "        }  # only one function in this example, but you can have multiple\n",
    "        function_name = response_message[\"function_call\"][\"name\"]\n",
    "        function_to_call = available_functions[function_name]\n",
    "        function_args = json.loads(response_message[\"function_call\"][\"arguments\"])\n",
    "        function_response = function_to_call(\n",
    "            location=function_args.get(\"location\"),\n",
    "            unit=function_args.get(\"unit\"),\n",
    "        )\n",
    "\n",
    "        # Step 4: send the info on the function call and function response to GPT\n",
    "        messages.append(response_message)  # extend conversation with assistant's reply\n",
    "        messages.append(\n",
    "            {\n",
    "                \"role\": \"function\",\n",
    "                \"name\": function_name,\n",
    "                \"content\": function_response,\n",
    "            }\n",
    "        )  # extend conversation with function response\n",
    "        second_response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo-0613\",\n",
    "            messages=messages,\n",
    "        )  # get a new response from GPT where it can see the function response\n",
    "        return second_response[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "print(run_conversation())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59e70e7-0e05-4f17-96f1-69314d86c772",
   "metadata": {},
   "source": [
    "**Ù…Ù…Ú©Ù† Ø§Ø³Øª Ù…Ø¯Ù„ Ø¨Ø®ÙˆØ§Ù‡Ø¯ ØªÙˆØ§Ø¨Ø¹ÛŒ Ø±Ø§ ÙØ±Ø§Ø®ÙˆØ§Ù†ÛŒ Ú©Ù†Ø¯ Ú©Ù‡ Ø¨Ù‡Ø´ Ø§Ø±Ø§Ø¦Ù‡ Ù†Ø´Ø¯Ù‡ØŒ Ø¨Ø±Ø§ÛŒ Ø±ÙØ¹ Ø§ÛŒÙ† Ù…Ø´Ú©Ù„ Ø§Ø² ÛŒÚ© Ù¾ÛŒØ§Ù… Ø¨Ø§ Ù†Ù‚Ø´ Ø³ÛŒØ³ØªÙ… Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯ Ùˆ Ø¨Ú¯ÛŒØ¯ Ú©Ù‡ ÙÙ‚Ø· Ø§Ø² ØªÙˆØ§Ø¨Ø¹ÛŒ Ú©Ù‡ Ø§Ø±Ø§Ø¦Ù‡ Ø´Ø¯Ù‡ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
